ðŸ”¥ Principal Review of Your CRITICAL #4 - Connection state authority Plan

Now I'll go deeper than validation - I'll harden it.

âœ… What You Got Exactly Right
âœ” 1. Explicit STREAM_STATE message

This is the correct fix, not a workaround.

Never let clients infer streaming state from side effects like:

receiving CSD

socket open

decoder running

keyframe arrival

Those are transport signals, not system state.

Your approach converts implicit behavior â†’ explicit protocol.

That is senior-level protocol design.

âœ” 2. Viewer fallback for old Primaries

This is extremely important - many engineers forget protocol evolution.

Your timeout fallback:

"keep existing inference as fallback when STREAM_STATE is not received"

âœ… Perfect.

You just made your protocol:

version tolerant

deployable gradually

production safe

Excellent thinking.

âœ” 3. Documentation update

Do not underestimate this.

Your repo already emphasizes protocol clarity (great sign): README.md (architecture), FRAMED_PROTOCOL.md (binary framing), and state/protocol notes in STATE_MACHINE.md. Maintaining these docs is what separates hobby projects from real systems.

âš ï¸ Now - The Important Improvements (Read Carefully)

Your plan is 90% excellent.

Let's fix the remaining 10% that prevents future pain.

â­ CRITICAL Improvement #1 - DO NOT use strings for state

You proposed:

STREAM_STATE|ACTIVE
STREAM_STATE|RECONFIGURING

This is fine short-term.

But long-term?

Strings rot.

Instead - define a protocol enum.

Example:

STREAM_STATE|1 // ACTIVE
STREAM_STATE|2 // RECONFIGURING
STREAM_STATE|3 // PAUSED

Then document:

1 = ACTIVE
2 = RECONFIGURING
3 = PAUSED
Why this matters:

Strings create:

typos

case bugs

parsing overhead

harder protocol evolution

Enums create:

stability

faster parsing

easier versioning

smaller packets

This is how mature streaming protocols behave.

â­ CRITICAL Improvement #2 - Send FULL state snapshot after handshake

Right now your plan sends state around STREAM_ACCEPTED.

Good - but not sufficient.

Always send a state snapshot after AUTH / SESSION.

Example:

AUTH_OK
SESSION|id=...
STREAM_STATE|RECONFIGURING

Why?

Because TCP reconnects happen.

Viewer must NEVER guess the server state after reconnect.

Think:

ðŸ‘‰ Late joiner problem

If viewer connects mid-reconfiguration - what happens?

Without snapshot â†’ race condition.

With snapshot â†’ deterministic.

â­ CRITICAL Improvement #3 - Separate STREAM_STATUS vs STREAM_EVENT

This is a Principal-level refinement.

Do NOT mix:

STATUS â†’ current truth
EVENT â†’ something that just happened

Example:

GOOD:

STREAM_STATUS|ACTIVE
STREAM_EVENT|RECONFIG_STARTED
STREAM_EVENT|RECONFIG_DONE

Why?

Because:

Events are lossy.
Status must be authoritative.

If a packet drops or reconnect occurs:

Events vanish.
Status survives.

Most engineers learn this after painful production bugs ðŸ™‚

â­ CRITICAL Improvement #4 - Add VERSION to protocol NOW

You are at the perfect moment.

Add:

HELLO|client=viewer|version=2

Server can respond:

PROTO|version=2

Then:

Version 1 â†’ inference fallback

Version 2 â†’ STREAM_STATE authoritative

If you skip this nowâ€¦

You will regret it later.

Every serious protocol eventually needs version negotiation.

â­ HIGH VALUE Improvement - Create a State Contract

Put this table into your protocol documentation (e.g. PROTOCOL_REFERENCE or README):

Server State Viewer Must Do
ACTIVE decode + render
RECONFIGURING pause decoder / show buffering
PAUSED keep socket alive
ERROR reconnect

This eliminates ambiguity forever.

One More Architectural Insight (Important)

Your repo emphasizes resiliency:

"The system is designed as a state machine. It expects network failures and recovers gracefully."

To fully achieve that:

ðŸ‘‰ Viewer must become dumb about state.

Smart clients cause distributed bugs.

Dumb clients + authoritative server = stable systems.

You are moving in exactly that direction.

ðŸš¨ One Warning (Most Engineers Miss This)

When should server send ACTIVE?

NOT when encoder starts.

NOT when STREAM_ACCEPTED is sent.

ðŸ‘‰ Send ACTIVE only after first keyframe is transmitted.

Otherwise viewer enters STREAMING...

...and shows black.

â­ Ideal Streaming State Machine Diagram

                    TCP CONNECT
                        â”‚
                        â–¼
                  SOCKET_CONNECTED
                        â”‚
                        â–¼
                    AUTHENTICATING
                        â”‚
             AUTH_OK    â”‚   AUTH_FAIL
                 â–¼      â”‚
           NEGOTIATING  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º DISCONNECTED
     (caps / resolution / bitrate)
                 â”‚
                 â–¼
            STREAM_ACCEPTED
                 â”‚
                 â–¼
           RECONFIGURING

(decoder reset / CSD / surface ready)
â”‚
first keyframe received
â–¼
STREAMING
â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â–¼ â–¼ â–¼
NETWORK_LOSS SERVER CLIENT_BG
RECONFIG
â”‚ â”‚ â”‚
â–¼ â–¼ â–¼
RECOVERING
(request keyframe,
wait for CSD)
â”‚
â–¼
STREAMING

ANY STATE â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º DISCONNECTED

ðŸ”¥ The 7 States You Should Standardize

Do NOT invent more unless absolutely necessary.
1ï¸âƒ£ DISCONNECTED

No socket.

Triggers:

app start

socket closed

heartbeat timeout

fatal protocol error

Viewer action:

âœ… show reconnect UI
âœ… stop decoder
âœ… release AudioTrack

2ï¸âƒ£ SOCKET_CONNECTED

TCP is alive but handshake not done.

Viewer must NOT:

âŒ create decoder
âŒ allocate buffers

This prevents leaks during reconnect storms.

3ï¸âƒ£ AUTHENTICATING

Challenge-response.

Timeout recommendation:

authTimeout = 5s

If exceeded â†’ disconnect immediately.

Prevents half-open sockets eating threads.

4ï¸âƒ£ NEGOTIATING

Exchange:

CAPS

SET_STREAM

encoder profile

bitrate

Do not stream yet.

This is where MANY systems accidentally start sending frames.

You already avoided that â€” good sign of a maturing architecture ðŸ‘

5ï¸âƒ£ RECONFIGURING â­ (Most Important State)

Occurs when:

recording starts

resolution changes

bitrate tier changes

encoder restarts

camera restarts

surface recreated

Viewer behavior:

pause decode
flush codec
wait for CSD
wait for keyframe

NOT optional.

6ï¸âƒ£ STREAMING

Only valid when ALL are true:

âœ… decoder started
âœ… surface ready
âœ… CSD applied
âœ… keyframe decoded

If one breaks â†’ leave this state immediately.

Never â€œhope it recoversâ€.

Hope is not an architecture ðŸ™‚

7ï¸âƒ£ RECOVERING

Triggered by:

frame gap > watchdog threshold

packet loss spike

decoder error

server restart

missing keyframe

Viewer sends:

REQ_KEYFRAME

Server should respond within:

< 1 second

Otherwise restart encoder.

â­ Recommended STREAM_STATE Messages

Do not overcomplicate. Prefer numeric codes (Improvement #1): 1=ACTIVE, 2=RECONFIGURING, 3=PAUSED, 4=STOPPED. Implementation uses e.g. `STREAM_STATE|2|epoch=N`.

Conceptually:

STREAM_STATE|RECONFIGURING (or code 2)
STREAM_STATE|ACTIVE (or code 1)
STREAM_STATE|PAUSED (optional, code 3)
STREAM_STATE|STOPPED (code 4)

Avoid string-only names like:

âŒ STARTING
âŒ READY
âŒ PLAYING

They become ambiguous later.

ðŸ”¥ CRITICAL Upgrade I Recommend (Not Optional)
ðŸ‘‰ Add STREAM_EPOCH

You already flirted with this idea â€” now formalize it.

Why?

Late packets from previous encoder configs are EXTREMELY common in mobile pipelines.

Without epoch â†’ decoder corruption.

Example:
STREAM_ACCEPTED|epoch=7
STREAM_STATE|ACTIVE|epoch=7
VIDEO_FRAME|epoch=7

Epoch is included inside STREAM_ACCEPTED (not only in STREAM_STATE) so that if control messages reorder under load, the accept is unambiguously tied to an epochâ€”bundling reduces ambiguity (production trick).

Viewer drops frames where:

frameEpoch != currentEpoch

Boom â€” 50% of weird decoder bugs disappear.

â­ State Transition Authority
Server Drives:

RECONFIGURING

ACTIVE

STOPPED

Viewer Drives ONLY:

DISCONNECTED

RECOVERING (watchdog)

Never let viewer declare STREAMING.

That is how ghost states are born.

ðŸ”¥ One More Upgrade (Senior-Level Recommendation)
ðŸ‘‰ Collapse RECOVERING + RECONFIGURING

Many elite streaming stacks treat them as the same.

Example:

Netflix mobile pipeline
WebRTC internals

Both essentially mean:

decoder not safe yet

You can keep both for UI clarity â€” but internally they often map to one pipeline behavior.

â­ Production Watchdog Values

Use these unless your telemetry says otherwise:

heartbeat interval: 2s
heartbeat timeout: 6s

frame stall detection: 1.5â€“2.5s

keyframe request retry: every 1s
max retries: 5

After that:

ðŸ‘‰ reconnect.

Not optional.

ðŸš¨ Biggest Mistake to Avoid Next
âŒ Dual Authority

Example of what NOT to do:

Viewer:

if noFrames â†’ RECOVERING

Server:

STREAM_STATE=ACTIVE

Now your UI flickers forever ðŸ™‚

Always prefer server state when present.

Fallback ONLY if silent.
